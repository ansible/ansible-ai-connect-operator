---
apiVersion: v1
kind: ConfigMap
metadata:
  name: '{{ ansible_operator_meta.name }}-{{ deployment_type }}-llama-stack-config'
  namespace: '{{ ansible_operator_meta.namespace }}'
  labels:
    {{ lookup("template", "../common/templates/labels/common.yaml.j2") | indent(width=4) | trim }}
data:
  ansible-chatbot-run.yaml: |
    version: '2'
    image_name: ansible-chatbot
    container_image: ansible-chatbot
    apis:
      - inference
      - vector_io
      - safety
      - agents
      - datasetio
      - telemetry
      - tool_runtime
      - files
    providers:
      inference:
        - provider_id: {{ chatbot_llm_provider_type }}
{% if chatbot_llm_provider_type == "openai" %}
          provider_type: remote::openai
          config:
            api_key: ${env.PROVIDER_TOKEN}
            base_url: ${env.PROVIDER_URL:=https://api.openai.com/v1}
{% elif chatbot_llm_provider_type == "azure_openai" %}
          provider_type: remote::azure
          config:
            api_key: ${env.PROVIDER_TOKEN}
            api_base: ${env.PROVIDER_URL}
            api_type: null
{% elif chatbot_llm_provider_type == "rhoai_vllm" %}
          provider_type: remote::vllm
          config:
            url: ${env.PROVIDER_URL}
            max_tokens: ${env.VLLM_MAX_TOKENS:=4096}
            api_token: ${env.PROVIDER_TOKEN:=fake}
            tls_verify: ${env.VLLM_TLS_VERIFY:=true}
{% endif %}
{% for key, value in chatbot_model_config_extras.items() %}
            {{ key }}: {{ value }}
{% endfor %}
        - provider_id: inline_sentence-transformer
          provider_type: inline::sentence-transformers
          config: {}
      vector_io:
        - provider_id: aap_faiss
          provider_type: inline::faiss
          config:
            kvstore:
              type: sqlite
              namespace: null
              db_path: ${env.VECTOR_DB_DIR:=/.llama/data/distributions/ansible-chatbot}/aap_faiss_store.db
      safety:
        - provider_id: llama-guard
          provider_type: inline::llama-guard
          config:
            excluded_categories: []
      agents:
        - provider_id: lightspeed_inline_agent
          provider_type: inline::lightspeed_inline_agent
          config:
            persistence_store:
              type: sqlite
              namespace: null
              db_path: ${env.PROVIDERS_DB_DIR:=/.llama/data/distributions/ansible-chatbot}/agents_store.db
            responses_store:
              type: sqlite
              namespace: null
              db_path: ${env.PROVIDERS_DB_DIR:=/.llama/data/distributions/ansible-chatbot}/responses_store.db
            tools_filter:
              enabled: true
              model_id: ${env.INFERENCE_MODEL_FILTER:=}
              always_include_tools:
              - knowledge_search
      datasetio:
        - provider_id: localfs
          provider_type: inline::localfs
          config:
            kvstore:
              type: sqlite
              namespace: null
              db_path: ${env.PROVIDERS_DB_DIR:=/.llama/data/distributions/ansible-chatbot}/localfs_datasetio.db
      files:
        - provider_id: localfs
          provider_type: inline::localfs
          config:
            storage_dir: ${env.PROVIDERS_DB_DIR:=/.llama/data/distributions/ansible-chatbot}/files
            metadata_store:
              type: sqlite
              namespace: null
              db_path: ${env.PROVIDERS_DB_DIR:=/.llama/data/distributions/ansible-chatbot}/files_store.db
      telemetry:
        - provider_id: meta-reference
          provider_type: inline::meta-reference
          config:
            service_name: ${env.OTEL_SERVICE_NAME:=ansible-chatbot-stack}
            sinks: ${env.TELEMETRY_SINKS:=console,sqlite}
            sqlite_db_path: ${env.PROVIDERS_DB_DIR:=/.llama/data/distributions/ansible-chatbot}/trace_store.db
      tool_runtime:
        - provider_id: rag-runtime
          provider_type: inline::rag-runtime
          config: {}
        - provider_id: model-context-protocol
          provider_type: remote::model-context-protocol
          config: {}
    metadata_store:
      namespace: null
      type: sqlite
      db_path: ${env.PROVIDERS_DB_DIR:=/.llama/data/distributions/ansible-chatbot}/registry.db
    models:
      - metadata: {}
        model_id: ${env.INFERENCE_MODEL}
        provider_id: {{ chatbot_llm_provider_type }}
        provider_model_id: ${env.INFERENCE_MODEL}
      - metadata:
          embedding_dimension: 768
        model_id: ${env.EMBEDDINGS_MODEL:=/.llama/data/distributions/ansible-chatbot/embeddings_model}
        provider_id: inline_sentence-transformer
        model_type: embedding
    shields: []
    vector_dbs:
      - metadata: {}
        vector_db_id: "aap-product-docs-2_6"
        provider_vector_db_id: ${env.PROVIDER_VECTOR_DB_ID:=}
        embedding_model: ${env.EMBEDDINGS_MODEL:=/.llama/data/distributions/ansible-chatbot/embeddings_model}
        embedding_dimension: 768
        provider_id: "aap_faiss"
    datasets: []
    scoring_fns: []
    benchmarks: []
    tool_groups:
      - toolgroup_id: builtin::rag
        provider_id: rag-runtime
{% if _aap_gateway_url is defined and _aap_controller_url is defined %}
      - toolgroup_id: mcp::aap-controller
        provider_id: model-context-protocol
        mcp_endpoint:
          uri: http://127.0.0.1:8004/sse
{% endif %}
{% if _aap_gateway_url is defined %}
      - toolgroup_id: mcp::aap-lightspeed
        provider_id: model-context-protocol
        mcp_endpoint:
          uri: http://127.0.0.1:8005/sse
{% endif %}
    logging: null
    server:
      port: 8443
      tls_certfile: null
      tls_keyfile: null
      tls_cafile: null
      auth: null
      disable_ipv6: false
    external_providers_dir: ${env.EXTERNAL_PROVIDERS_DIR:=/.llama/providers.d}
