---
# Read Chatbot configuration secret
- name: Read Chatbot configuration
  kubernetes.core.k8s_info:
    kind: Secret
    namespace: '{{ ansible_operator_meta.namespace }}'
    name: '{{ chatbot_config_secret_name }}'
  register: _chatbot_config_resource
  no_log: "{{ no_log }}"

- name: Validate 'chatbot_config_secret_name'
  ansible.builtin.fail:
    msg: |
      Secret {{ chatbot_config_secret_name }} could not be found.
  when: _chatbot_config_resource["resources"] | length == 0

# Validate Chatbot configuration
- name: Validate 'chatbot_model'
  ansible.builtin.fail:
    msg: |
      You must specify a 'chatbot_model' in your Secret.
  when: not _chatbot_config_resource["resources"][0]["data"].chatbot_model

- name: Set Chatbot model
  ansible.builtin.set_fact:
    chatbot_model: '{{ _chatbot_config_resource["resources"][0]["data"].chatbot_model | b64decode }}'
  no_log: "{{ no_log }}"

- name: Validate 'chatbot_url'
  ansible.builtin.fail:
    msg: |
      You must specify a 'chatbot_url' in your Secret.
  when: not _chatbot_config_resource["resources"][0]["data"].chatbot_url

- name: Set Chatbot URL
  ansible.builtin.set_fact:
    chatbot_url: '{{ _chatbot_config_resource["resources"][0]["data"].chatbot_url | b64decode }}'
  no_log: "{{ no_log }}"

- name: Validate 'chatbot_token'
  ansible.builtin.fail:
    msg: |
      You must specify a 'chatbot_token' in your Secret.
  when: not _chatbot_config_resource["resources"][0]["data"].chatbot_token

- name: Set Chatbot Configuration
  ansible.builtin.set_fact:
    chatbot_config: '{{ _chatbot_config_resource }}'
  no_log: "{{ no_log }}"

- name: Set LLM provider type if it is defined in the config
  ansible.builtin.set_fact:
    chatbot_llm_provider_type: '{{ _chatbot_config_resource["resources"][0]["data"].chatbot_llm_provider_type | b64decode }}'
  no_log: "{{ no_log }}"
  when: _chatbot_config_resource["resources"][0]["data"].chatbot_llm_provider_type is defined

- name: Validate watsonx.ai project ID if LLM provider type is set to "watsonx"
  ansible.builtin.fail:
    msg: |
      You must specify a 'chatbot_llm_provider_project_id' in your Secret when 'chatbot_llm_provider_type' is set to 'watsonx'
  when:
    - chatbot_llm_provider_type is defined
    - chatbot_llm_provider_type == "watsonx"
    - not _chatbot_config_resource["resources"][0]["data"].chatbot_llm_provider_project_id is defined

- name: Set watsonx.ai project ID if it is defined in the config
  ansible.builtin.set_fact:
    chatbot_llm_provider_project_id: '{{ _chatbot_config_resource["resources"][0]["data"].chatbot_llm_provider_project_id | b64decode }}'
  no_log: "{{ no_log }}"
  when: _chatbot_config_resource["resources"][0]["data"].chatbot_llm_provider_project_id is defined

- name: Set context window size if it is defined in the config
  ansible.builtin.set_fact:
    chatbot_context_window_size: '{{ _chatbot_config_resource["resources"][0]["data"].chatbot_context_window_size | b64decode | int }}'
  no_log: "{{ no_log }}"
  when: _chatbot_config_resource["resources"][0]["data"].chatbot_context_window_size is defined

- name: Set LLM temperature parameter override if it is defined in the config
  ansible.builtin.set_fact:
    chatbot_temperature_override: '{{ _chatbot_config_resource["resources"][0]["data"].chatbot_temperature_override | b64decode }}'
  no_log: "{{ no_log }}"
  when: _chatbot_config_resource["resources"][0]["data"].chatbot_temperature_override is defined

- name: Set Azure AI deployment name if it is defined in the config
  ansible.builtin.set_fact:
    chatbot_azure_deployment_name: '{{ _chatbot_config_resource["resources"][0]["data"].chatbot_azure_deployment_name | b64decode }}'
  no_log: "{{ no_log }}"
  when:
    - chatbot_llm_provider_type is defined
    - chatbot_llm_provider_type == "azure_openai"
    - _chatbot_config_resource["resources"][0]["data"].chatbot_azure_deployment_name is defined

- name: Set Azure AI API version if it is defined in the config
  ansible.builtin.set_fact:
    chatbot_azure_api_version: '{{ _chatbot_config_resource["resources"][0]["data"].chatbot_azure_api_version | b64decode }}'
  no_log: "{{ no_log }}"
  when:
    - chatbot_llm_provider_type is defined
    - chatbot_llm_provider_type == "azure_openai"
    - _chatbot_config_resource["resources"][0]["data"].chatbot_azure_api_version is defined

- name: Set Chatbot Include Fake LLMs to false if it is not defined in the config
  ansible.builtin.set_fact:
    chatbot_include_fake_llms: false
  no_log: "{{ no_log }}"
  when: not _chatbot_config_resource["resources"][0]["data"].chatbot_include_fake_llms is defined

- name: Set Chatbot Include Fake LLMs if it is defined in the config
  ansible.builtin.set_fact:
    chatbot_include_fake_llms: '{{ _chatbot_config_resource["resources"][0]["data"].chatbot_include_fake_llms | default(false) | b64decode }}'
  no_log: "{{ no_log }}"
  when: _chatbot_config_resource["resources"][0]["data"].chatbot_include_fake_llms is defined

- name: Set Chatbot Fake Streaming Chunks
  ansible.builtin.set_fact:
    chatbot_fake_streaming_chunks: '{{ _chatbot_config_resource["resources"][0]["data"].chatbot_fake_streaming_chunks | b64decode }}'
  no_log: "{{ no_log }}"
  when: _chatbot_config_resource["resources"][0]["data"].chatbot_fake_streaming_chunks is defined

- name: Set Chatbot Fake Streaming Sleep
  ansible.builtin.set_fact:
    chatbot_fake_streaming_sleep: '{{ _chatbot_config_resource["resources"][0]["data"].chatbot_fake_streaming_sleep | b64decode }}'
  no_log: "{{ no_log }}"
  when: _chatbot_config_resource["resources"][0]["data"].chatbot_fake_streaming_sleep is defined
